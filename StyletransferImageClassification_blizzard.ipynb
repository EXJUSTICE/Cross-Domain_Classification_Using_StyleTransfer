{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StyletransferImageClassification_BLIZipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gyG4OC_n_Bgb","colab_type":"text"},"source":["Based on Object detection and Classification Kaggle notebook using natural-images dataset by navidrashik.\n","\n","This notebook generates a reference for use on our test dataset\n","\n","-TODO: #MAKE A TEST DATAGEN linking to separate path\n","\n","#https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n","\n","#TODO DELETE BOTH AIRPLANE AND PERSON"]},{"cell_type":"code","metadata":{"id":"JHtRS9Wf9mZc","colab_type":"code","outputId":"3823c7fe-ad49-4df7-8c46-18b21b494761","executionInfo":{"status":"ok","timestamp":1557316253426,"user_tz":-480,"elapsed":19911,"user":{"displayName":"Yijie Xu","photoUrl":"","userId":"14695674479284134427"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["\n","\n","# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","#set randomness for reproducibility\n","from numpy.random import seed\n","#seed(6) #1\n","from tensorflow import set_random_seed\n","#set_random_seed(5) #2\n","\n","#\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","import os\n","\n","\n","#TRAINING SETS########################################\n","\n","#Download the training dataset- REFERENCE\n","\n","#!gdown https://drive.google.com/uc?id=1yYHVSKhMaUM19LuGHo07Hor8Xujxk2uD\n","\n","\n","\n","#Download the training dataset -STLYLED 20%\n","\n","#!gdown https://drive.google.com/uc?id=1lXWngntuZf3xgJK0cetlbP5i8XgaOwXf\n","\n","\n","\n","\n","  \n","#Download the training dataset -Blizzard 20%\n","\n","!gdown https://drive.google.com/uc?id=1bN68zyY4Aq5hFXDKPAifN-UOGW3Vuzah\n","\n","#TEST SETS\n","\n","#Download the test dataset- blizzard\n"," \n","#!gdown https://drive.google.com/uc?id=1I-EzDmkYwnnN189W09PX47Sj4d6TuLjj\n","\n","  \n","#Download test dataset- snow landscapes\n","!gdown https://drive.google.com/uc?id=1Jq76RNjpsDexJMQMWMNjpOZMRHV1_anP\n","\n","\n","#Download test dataset- styled\n","#!gdown https://drive.google.com/uc?id=17IMXL-nQTDg3sOQbyL7s6Z-CtjRrvlLg\n","  \n","  \n","\n","\n","#Unzip all folders\n","\n","!unzip natural_images_blizzard.zip\n","!unzip snow.zip\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1bN68zyY4Aq5hFXDKPAifN-UOGW3Vuzah\n","To: /content/natural_images_blizzard.zip\n","89.5MB [00:00, 146MB/s] \n","Downloading...\n","From: https://drive.google.com/uc?id=1Jq76RNjpsDexJMQMWMNjpOZMRHV1_anP\n","To: /content/snow.zip\n","2.46MB [00:00, 76.7MB/s]\n","Archive:  natural_images_blizzard.zip\n","replace natural_images_blizzard/car/blizzard (1).jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cvTuKxbA_6Qx","colab_type":"code","colab":{}},"source":["print(os.listdir(\"/content/\"))\n","\n","#Print and remove zips once done\n","\n","!rm snow.zip\n","!rm natural_images_blizzard.zip\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"923QFSnj-E_1","colab_type":"code","colab":{}},"source":["from os import listdir\n","data_list = listdir('/content/natural_images_blizzard/')\n","\n","#Delete some classes that may interfere\n","\n","!cd natural_images_styled\n","#!rm -r natural_images_styled/flower\n","#!rm -r natural_images/motorbike\n","#!rm -r natural_images/airplane\n","\n","data_list"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SW7NXqkh-Gk8","colab_type":"text"},"source":["Resnet Initialization"]},{"cell_type":"code","metadata":{"id":"0BfmpmKd-JOb","colab_type":"code","colab":{}},"source":["from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model ,load_model\n","from tensorflow.keras.layers import Flatten, Dense, Dropout\n","from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n","from tensorflow.keras.optimizers import Adam, RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","import numpy as np\n","import tensorflow as tf\n","\n","\n","DATASET_PATH  = '/content/natural_images_blizzard'\n","test_dir = 'snow/'\n","IMAGE_SIZE    = (224, 224)\n","NUM_CLASSES   = len(data_list)\n","BATCH_SIZE    = 20  # try reducing batch size or freeze more layers if your GPU runs out of memory\n","FREEZE_LAYERS = 16 # freeze the first this many layers for training\n","NUM_EPOCHS    = 10\n","LEARNING_RATE = 5e-5 #Slow learn rate as we are transfer training5e-5\n","DROP_OUT = .5\n","\n","\n","\n","#Train datagen here is a preprocessor\n","train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n","                                   rotation_range=50,\n","                                   featurewise_center = True,\n","                                   featurewise_std_normalization = True,\n","                                   width_shift_range=0.2,\n","                                   height_shift_range=0.2,\n","                                   shear_range=0.25,\n","                                   zoom_range=0.1,\n","                                   zca_whitening = True,\n","                                   channel_shift_range = 20,\n","                                   horizontal_flip = True ,\n","                                   vertical_flip = True ,\n","                                   validation_split = 0.2,\n","                                   fill_mode='constant')\n","\n","# test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n","#                                    fill_mode='constant')\n","\n","train_batches = train_datagen.flow_from_directory(DATASET_PATH,\n","                                                  target_size=IMAGE_SIZE,\n","                                                  shuffle=True,\n","                                                  batch_size=BATCH_SIZE,\n","                                                  subset = \"training\"\n","                                                  )\n","\n","valid_batches = train_datagen.flow_from_directory(DATASET_PATH,\n","                                                  target_size=IMAGE_SIZE,\n","                                                  shuffle=True,\n","                                                  batch_size=BATCH_SIZE,\n","                                                  subset = \"validation\"\n","                                                 \n","                                                  )\n","\n","#MAKE A TEST DATAGEN linking to separate path\n","#train_batches\n","\n","#https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Arc_63PU-O5K","colab_type":"text"},"source":["Layer Modification at upper layer of Resnet"]},{"cell_type":"code","metadata":{"id":"FQa8cRGT-MLC","colab_type":"code","colab":{}},"source":["# build our classifier model based on pre-trained InceptionResNetV2:\n","# 1. we don't include the top (fully connected) layers of InceptionResNetV2\n","# 2. we add a DropOut layer followed by a Dense (fully connected)\n","#    layer which generates softmax class score for each class\n","# 3. we compile the final model using an Adam optimizer, with a\n","#    low learning rate (since we are 'fine-tuning')\n","\n","#############main portion for vgg16 only##############\n","net = InceptionResNetV2(include_top=True,\n","                        weights='imagenet',\n","                        input_tensor=None,\n","                        input_shape=(299,299,3))\n","\n","  ############## Run this block if include top = False ######\n","#   x = net.output\n","#   x = Flatten()(x)\n","#   x = Dropout(DROP_OUT)(x)\n","###############   End of block ##################\n","\n","############## Run this block if include top = True ######\n","'''This block keeps avg_pool (GlobalAveragePooling2) layer and removes only prediction layer.\n","Then replace inceptionResnetv2's predictionlayer with a drpout layer and and a softmax layer. \n","To change the class class size of 1000 to 8 we need to replace their pediction layer with our softmax layer.\n","'''\n","avg_pool = net.layers[-2]\n","prediction = net.layers[-1]\n","\n","#create drpout layer\n","drp1 = Dropout(DROP_OUT)\n","x = drp1(avg_pool.output)\n","###############   End of block ##################\n","\n","\n","\n","output_layer = Dense(5, activation='softmax', name='softmax')(x)\n","net_final = Model(inputs=net.input, outputs=output_layer)\n","\n","for layer in net_final.layers[:FREEZE_LAYERS]:\n","    layer.trainable = False\n","\n","for layer in net_final.layers[FREEZE_LAYERS:]:\n","    layer.trainable = True\n","\n","net_final.compile(optimizer=Adam(lr=LEARNING_RATE),\n","                  loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","#   print(net_final.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKDLJZjL-UlA","colab_type":"code","colab":{}},"source":["print(net_final.summary())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Sr9B1KFktza","colab_type":"code","colab":{}},"source":["#Adding Dropout layer to a pre trained model\n","drpout_needed = False\n","\n","if drpout_needed :\n","  flt = net_final.layers[-2]\n","  prediction = net_final.layers[-1]\n","\n","  #create drpout layer\n","  drp1 = Dropout(DROP_OUT)\n","  x = drp1(flt.output)\n","\n","  predictors = prediction(x)\n","  net_final = Model(inputs=net_final.input, outputs=predictors)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qh3QQZLz-yLW","colab_type":"text"},"source":["Training"]},{"cell_type":"code","metadata":{"id":"F7IwDhx5-iKe","colab_type":"code","colab":{}},"source":["#FIT MODEL\n","result=net_final.fit_generator(train_batches,\n","                        steps_per_epoch = np.ceil(len(train_batches) / BATCH_SIZE),\n","                        validation_data = valid_batches,\n","                        validation_steps = np.ceil(len(valid_batches) / BATCH_SIZE),\n","                        epochs = NUM_EPOCHS,\n","#                         \n","                       )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNIFRzOvp1yA","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","\n","\n","def plot_acc_loss(result, epochs):\n","    acc = result.history['acc']\n","    loss = result.history['loss']\n","    val_acc = result.history['val_acc']\n","    val_loss = result.history['val_loss']\n","    plt.figure(figsize=(15, 5))\n","    plt.subplot(121)\n","    plt.plot(range(epochs), acc, label='Train_acc')\n","    plt.plot(range(epochs), val_acc, label='Test_acc')\n","    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n","    plt.legend()\n","    plt.grid(True)\n","    plt.subplot(122)\n","    plt.plot(range(epochs), loss, label='Train_loss')\n","    plt.plot(range(epochs), val_loss, label='Test_loss')\n","    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","    \n","plot_acc_loss(result, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1W_MvpGJ39q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iK6brzE2-z08","colab_type":"code","colab":{}},"source":["# save trained weights\n","# net_final.save(WEIGHTS_FINAL)\n","x = net_final.evaluate_generator(valid_batches,\n","                           steps = np.ceil(len(valid_batches) / BATCH_SIZE),\n","                           use_multiprocessing = True,\n","                           verbose = 1\n","                           )\n","\n","\n","print('Test loss:' , x[0])\n","print('Test accuracy:',x[1])\n","\n","#net_final.save('stylgen_recog_styled_10.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5X6TGa0N-5R0","colab_type":"text"},"source":["Predict"]},{"cell_type":"code","metadata":{"id":"B1Qqa6YG-6kB","colab_type":"code","colab":{}},"source":["#Evaluate on test dataset - TODO: actually import the test dataset define TESTdir, we also have to name all of it as CAR\n","\n","\n","eval_generator = train_datagen.flow_from_directory(\n","        test_dir,target_size=IMAGE_SIZE,\n","        batch_size=20,\n","        class_mode='categorical')\n","eval_generator.reset()    \n","pred = net_final.predict_generator(eval_generator,1000,verbose=1)\n","print(\"Predictions finished\")\n","\n","\n","#Map the predictions to the training classes\n","#First, take max prediction class\n","predicted_class_indices=np.argmax(pred,axis=1)\n","\n","#Map it to train generataor\n","labels = (train_batches.class_indices)\n","labels = dict((v,k) for k,v in labels.items())\n","predictions = [labels[k] for k in predicted_class_indices]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JL6Qxxl9-8If","colab_type":"text"},"source":["Save"]},{"cell_type":"code","metadata":{"id":"Q7hNzKL1-8g2","colab_type":"code","colab":{}},"source":["#Save results\n","\n","filenames=eval_generator.filenames\n","results=pd.DataFrame({\"Filename\":filenames,\n","                      \"Predictions\":predictions})\n","results.to_csv(\"finalresultsVGG16_BLIZZARD_snowlandscape_25FROZEN50DROPOUT.csv\",index=False)"],"execution_count":0,"outputs":[]}]}